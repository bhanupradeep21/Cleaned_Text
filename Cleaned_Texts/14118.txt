emotional prosody affective prosody various nonverbal aspects language allow people convey understand includes individuals tone voice speech conveyed changes pitch loudness timbre speech rate pauses isolated semantic information interacts verbal content eg emotional prosody speech perceived decoded slightly worse facial expressions accuracy varies emotions anger sadness perceived easily followed fear happiness disgust poorly source needed studies found emotions fear joy anger portrayed higher frequency emotions decoding emotions speech includes three stages determining acoustic features creating meaningful connections features processing acoustic patterns relation connections established processing stage connections basic emotional knowledge stored separately memory network specific associations associations used form baseline emotional expressions encountered future emotional meanings speech implicitly automatically registered circumstances importance surrounding details event average listeners able perceive intended emotions exhibited rate significantly better chance chanceapproximately however error rates also high partly due observation listeners accurate emotional inference particular voices perceive emotions better vocal expressions anger sadness perceived easily fear happiness moderately wellperceived disgust low source language split two components verbal vocal channels verbal channel semantic content made speakers chosen words verbal channel semantic content speakers words determines meaning sentence way sentence spoken however change meaning vocal channel channel language conveys emotions felt speaker gives us listeners better idea intended meaning nuances channel expressed intonation intensity rhythm combined prosody usually channels convey emotion sometimes differ sarcasm irony two forms humor based incongruent neurological processes integrating verbal vocal prosodic components relatively unclear however assumed verbal content vocal processed different hemispheres brain verbal content composed syntactic semantic information processed left hemisphere syntactic information processed primarily frontal regions small part temporal lobe brain semantic information processed primarily temporal regions smaller part frontal lobes incorporated contrast prosody processed primarily pathway verbal content right hemisphere neuroimaging studies using functional magnetic resonance imaging fmri machines provide support hemisphere lateralization temporofrontal activation studies however show evidence prosody perception exclusively lateralized right hemisphere may bilateral evidence basal ganglia may also play important role perception deficits expressing understanding prosody caused right hemisphere lesions known aprosodias manifest different forms various mental illnesses diseases aprosodia caused stroke alcohol abuse well types aprosodia include motor inability produce vocal inflection expressive brain limitations motor functions cause inability receptive person decipher emotional found gets increasingly difficult recognize vocal expressions emotion increasing age older adults slightly difficulty labeling vocal expressions emotion particularly sadness anger young adults much greater difficulty integrating vocal emotions corresponding facial expressions possible explanation difficulty combining two sources emotion requires greater activation emotion areas brain adults show decreased volume activity another possible explanation hearing loss could led mishearing vocal expressions high frequency hearing loss known begin occurring around age particularly right hemisphere brain associated prosody patients right hemisphere lesions difficulty varying speech patterns convey emotion speech may therefore sound monotonous addition people righthemisphere damage studied impaired comes identifying emotion intoned sentences difficulty decoding syntactic affective prosody also found people autism spectrum disorder schizophrenia patients deficits large number functional domains including social skills social cognition social impairments consist difficulties perceiving understanding anticipating reacting social cues crucial normal social interaction determined multiple studies hoekert et als study emotional prosody schizophrenia illustrated research must done fully confirm correlation illness emotional prosody however people schizophrenia problem deciphering nonemotional emotional states happiness sadness anger disgust determined solely based acoustic structure nonlinguistic speech act acts grunts sighs exclamations etc research supports notion nonlinguistic acts universal eliciting assumptions even speakers different languages addition proven emotion expressed nonlinguistic vocalizations differently speech laukka et al state speech requires highly precise coordinated movement articulators eg lips tongue larynx order transmit linguistic information whereas nonlinguistic vocalizations constrained linguistic codes thus require precise articulations entails nonlinguistic vocalizations exhibit larger ranges many acoustic features prosodic expressions study actors instructed vocalize array different emotions without words study showed listeners could identify wide range positive negative emotions chance however emotions like guilt pride less easily study verena kersken klaus zuberb√ºhler juancarlos gomez nonlinguistic vocalizations infants presented adults see adults could distinguish infant vocalizations indicating requests help pointing object indicating event infants show different prosodic elements crying depending crying also differing outbursts positive negative emotional states decipherment ability information determined applicable across cultures independent adults level experience infants men women differ use language also understand known difference rate speech range pitch duration speech pitch slope fitzsimmons et al example study relationship spectral prosodic signs established dependence pitch duration differed men women uttering sentences affirmative inquisitive intonation tempo speech pitch range pitch steepness differ genders nesic et al one illustration women likely speak faster elongate ends words raise pitch end sentences women men also different neurologically process emotional prosody fmri study men showed stronger activation cortical areas female subjects processing meaning manner emotional phrase manner task men activation bilateral middle temporal gyri women area significance right posterior cerebellar lobe male subjects study showed stronger activation prefrontal cortex average needed longer response time female subjects result interpreted mean men need make conscious inferences acts intentions speaker women may subconsciously therefore men needed integrate linguistic semantics emotional intent higher stage semantic processing research regarding vocal expression emotion studied use synthetic speech portrayals emotion professional actors little research done spontaneous natural speech samples artificial speech samples considered close natural speech specifically portrayals actors may influenced stereotypes emotional vocal expression may exhibit intensified characteristics speech skewing listeners perceptions another consideration lies listeners individual perceptions studies typically take average responses examine individual differences great depth may provide better insight vocal expressions httpsenwikipediaorgwikiemotionalprosody