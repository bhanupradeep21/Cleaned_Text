free energy principle theoretical framework suggesting brain reduces surprise uncertainty making predictions based internal models updating using sensory input highlights brains objective aligning internal model external world enhance prediction accuracy principle integrates bayesian inference active inference actions guided predictions sensory feedback refines wideranging implications comprehending brain function perception biophysics cognitive science free energy principle mathematical principle describing formal account representational capacities physical systems things exist look track properties systems establishes dynamics physical systems minimise quantity known surprisal negative log probability outcome equivalently variational upper bound called free energy principle used especially bayesian approaches brain function also approaches artificial intelligence formally related variational bayesian methods originally introduced karl friston explanation embodied perceptionaction loops free energy principle models behaviour systems distinct coupled another system eg embedding environment degrees freedom implement interface two systems known markov blanket formally free energy principle says system particular partition ie particles markov blankets subsets system track statistical structure subsets known internal external states paths system free energy principle based bayesian idea brain inference engine free energy principle systems pursue paths least surprise equivalently minimize difference predictions based model world sense associated perception difference quantified variational free energy minimized continuous correction world model system making world like predictions system actively changing world make closer expected state systems also minimize free energy system friston assumes principle biological friston also believes principle applies mental disorders well artificial intelligence ai implementations based active inference principle shown advantages free energy principle mathematical principle information physics much like principle maximum entropy principle least action true mathematical grounds attempt falsify free energy principle category mistake akin trying falsify calculus making empirical observations one invalidate mathematical theory way instead one would need derive formal contradiction theory interview friston explained entails free energy principle subject falsification think useful make fundamental distinction appeal later distinction state process theory ie difference normative principle things may may conform process theory hypothesis principle realized distinction free energy principle stands stark distinction things like predictive coding bayesian brain hypothesis free energy principle principle like hamiltons principle stationary action falsified disproven fact much unless ask whether measurable systems conform principle hand hypotheses brain performs form bayesian inference predictive coding hypotheses may may supported empirical many examples hypotheses supported empirical notion selforganising biological systems like cell brain understood minimising variational free energy based upon helmholtz work unconscious subsequent treatments machine variational free energy function observations probability density hidden causes variational density defined relation probabilistic model generates predicted observations hypothesized causes setting free energy provides approximation bayesian model therefore minimisation seen bayesian inference process system actively makes observations minimise free energy implicitly performs active inference maximises evidence model world however free energy also upper bound selfinformation outcomes longterm average surprise entropy means system acts minimise free energy implicitly place upper bound entropy outcomes sensory states active inference closely related good regulator related accounts selfassembly pattern formation addresses themes considered cybernetics embodied cognition free energy expressed expected energy observations variational density minus entropy also related maximum entropy finally time average energy action principle minimum variational free energy principle least action active inference allowing scale invariance also applied theories domains instance applied linguistics epidemiology among others negative free energy formally equivalent evidence lower bound commonly used machine learning train generative models variational autoencoders active inference applies techniques approximate bayesian inference infer causes sensory data generative model data caused uses inferences guide action bayes rule characterizes probabilistically optimal inversion causal model applying typically computationally intractable leading use approximate methods active inference leading class approximate methods variational methods practical theoretical reasons practical often lead simple inference procedures theoretical related fundamental physical principles discussed variational methods proceed minimizing upper bound divergence bayesoptimal inference posterior approximation according method upper bound known free energy accordingly characterize perception minimization free energy respect inbound sensory information action minimization free energy respect outbound action information holistic dual optimization characteristic active inference free energy principle hypothesis systems perceive act characterized way order exemplify mechanics active inference via free energy principle generative model must specified typically involves collection probability density functions together characterize causal model one specification follows system modelled inhabiting state space x displaystyle x sense states form points space state space factorized according x ψ r displaystyle xpsi times stimes atimes r ψ displaystyle psi space external states hidden agent sense directly perceived accessible displaystyle space sensory states directly perceived agent displaystyle space agents possible actions r displaystyle r space internal states private agent keeping figure note following ψ ψ displaystyle dot psi psi sa μ displaystyle mu functions continuous time displaystyle generative model specification following density functions density functions determine factors joint model represents complete specification generative model written bayes rule determines posterior density p ψ μ ψ displaystyle pdot psi samu psi expresses probabilistically optimal belief external state ψ displaystyle psi given preceding state agents actions sensory signals internal states since computing p bayes displaystyle ptextbayes computationally intractable free energy principle asserts existence variational density q ψ μ ψ displaystyle qdot psi samu psi q displaystyle q approximation p bayes displaystyle ptextbayes one defines free energy defines action perception joint optimization problem internal states μ displaystyle mu typically taken encode parameters variational density q displaystyle q hence agents best guess posterior belief ψ displaystyle psi note free energy also upper bound measure agents marginal average sensory surprise hence free energy minimization often motivated minimization surprise free energy minimisation proposed hallmark selforganising systems cast random dynamical formulation rests markov blanket comprising action sensory states separates internal external states internal states action minimise free energy place upper bound entropy sensory states ergodic assumptions longterm average surprise entropy bound resists natural tendency disorder sort associated second law thermodynamics fluctuation theorem however formulating unifying principle life sciences terms concepts statistical physics random dynamical system nonequilibrium steady state ergodicity places substantial constraints theoretical empirical study biological systems risk obscuring features make biological systems interesting kinds selforganizing bayesian inference cast terms free energy verification free energy minimised respect internal states divergence variational posterior density hidden states minimised corresponds approximate bayesian inference form variational density fixed exact bayesian inference otherwise free energy minimisation therefore provides generic description bayesian inference filtering eg kalman filtering also used bayesian model selection free energy usefully decomposed complexity accuracy models minimum free energy provide accurate explanation data complexity costs cf occams razor formal treatments computational complexity divergence variational density prior beliefs hidden states ie effective degrees freedom used explain data variational free energy informationtheoretic functional distinct thermodynamic helmholtz free however complexity term variational free energy shares fixed point helmholtz free energy assumption system thermodynamically closed isolated sensory perturbations suspended suitably long period time complexity minimised accuracy neglected point system equilibrium internal states minimise helmholtz free energy principle minimum free energy minimisation equivalent maximising mutual information sensory states internal states parameterise variational density fixed entropy variational density relates free energy minimization principle minimum redundancy free energy minimisation provides useful way formulate normative bayes optimal models neuronal inference learning therefore subscribes bayesian brain neuronal processes described free energy minimisation depend nature hidden states ψ x θ π displaystyle psi xtimes theta times pi comprise timedependent variables timeinvariant parameters precision inverse variance temperature random fluctuations minimising variables parameters precision correspond inference learning encoding uncertainty respectively free energy minimisation formalises notion unconscious inference provides normative bayesian theory neuronal processing associated process theory neuronal dynamics based minimising free energy gradient descent corresponds generalised bayesian filtering denotes variable generalised coordinates motion displaystyle derivative matrix usually generative models define free energy nonlinear hierarchical like cortical hierarchies brain special cases generalised filtering include kalman filtering formally equivalent predictive popular metaphor message passing brain hierarchical models predictive coding involves recurrent exchange ascending bottomup prediction errors descending topdown consistent anatomy physiology motor predictive coding optimising model parameters gradient descent time integral free energy free action reduces associative hebbian plasticity associated synaptic plasticity brain optimizing precision parameters corresponds optimizing gain prediction errors cf kalman gain neuronally plausible implementations predictive corresponds optimizing excitability superficial pyramidal cells interpreted terms attentional regard topdown vs bottomup controversy addressed major open problem attention computational model succeeded illustrating circular nature interplay topdown bottomup mechanisms using established emergent model attention namely saim authors proposed model called pesaim contrast standard version approaches selective attention topdown position model takes account transmission prediction errors level level order minimise energy function indicates difference data cause words generative model posterior increase validity also incorporated neural competition stimuli model notable feature model reformulation free energy function terms prediction errors task performance e l v p x n x c n k n n n x n c n b c n ε n c n b c n k ε k n k n displaystyle dfrac partial etotalyvpxsnxcnyknpartial ymnsnxmncnbcnvarepsilon nmcnbcnsum kvarepsilon knmkn e l displaystyle etotal total energy function neural networks entail ε k n k n displaystyle varepsilon knmkn prediction error generative model prior posterior changing comparing two models reveals notable similarity respective results also highlighting remarkable discrepancy whereby standard version saim models focus mainly upon excitatory connections whereas pesaim inhibitory connections leveraged make inference model also proved fit predict eeg fmri data drawn human experiments high precision vein yahya et al also applied free energy principle propose computational model template matching covert selective visual attention mostly relies according study total free energy whole statespace reached inserting topdown signals original neural networks whereby derive dynamical system comprising feedforward backward prediction error gradient descent applied action f μ displaystyle dot apartial afstilde mu motor control understood terms classical reflex arcs engaged descending corticospinal predictions provides formalism generalizes equilibrium point solution degrees freedom movement trajectories active inference related optimal control replacing value costtogo functions prior beliefs state transitions exploits close connection bayesian filtering solution bellman equation however active inference starts priors flow f γ v w displaystyle fgamma cdot nabla vnabla times w specified scalar v x displaystyle vx vector w x displaystyle wx value functions state space cf helmholtz decomposition γ displaystyle gamma amplitude random fluctuations cost c x f v γ v displaystyle cxfcdot nabla vnabla cdot gamma cdot v priors flow p x displaystyle ptilde xmid induce prior states p x exp v x displaystyle pxmid mexpvx solution appropriate forward kolmogorov contrast optimal control optimises flow given cost function assumption w displaystyle ie flow curl free detailed balance usually entails solving backward kolmogorov optimal decision problems usually formulated partially observable markov decision processes treated within active inference absorbing utility functions prior beliefs setting states high utility low cost states agent expects occupy equipping generative model hidden states model control policies control sequences minimise variational free energy lead high utility neurobiologically neuromodulators dopamine considered report precision prediction errors modulating gain principal cells encoding prediction closely related formally distinct role dopamine reporting prediction errors per related computational active inference used address range issues cognitive neuroscience brain function neuropsychiatry including action mirror saccades visual eye action explanations action active inference often depend idea brain stubborn predictions update leading actions cause predictions come httpsenwikipediaorgwikifreeenergyprinciple