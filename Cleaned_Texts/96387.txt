hebbian theory neuropsychological theory claiming increase synaptic efficacy arises presynaptic cells repeated persistent stimulation postsynaptic cell attempt explain synaptic plasticity adaptation brain neurons learning process introduced donald hebb book organization theory also called hebbs rule hebbs postulate cell assembly theory hebb states follows let us assume persistence repetition reverberatory activity trace tends induce lasting cellular changes add stability axon cell near enough excite cell b repeatedly persistently takes part firing growth process metabolic change takes place one cells efficiency one cells firing b theory often summarized cells fire together wire however hebb emphasized cell needs take part firing cell b causality occur cell fires time cell b aspect causation hebbs work foreshadowed known spiketimingdependent plasticity requires temporal theory attempts explain associative hebbian learning simultaneous activation cells leads pronounced increases synaptic strength cells also provides biological basis errorless learning methods education memory rehabilitation study neural networks cognitive function often regarded neuronal basis unsupervised learning hebbian theory concerns neurons might connect become engrams hebbs theories form function cell assemblies understood general idea old one two cells systems cells repeatedly active time tend become associated activity one facilitates activity hebb also one cell repeatedly assists firing another axon first cell develops synaptic knobs enlarges already exist contact soma second cell alan allport posits additional ideas regarding cell assembly theory role forming engrams along lines concept autoassociation described follows inputs system cause pattern activity occur repeatedly set active elements constituting pattern become increasingly strongly interassociated element tend turn every element negative weights turn elements form part pattern put another way pattern whole become autoassociated may call learned autoassociated pattern work laboratory eric kandel provided evidence involvement hebbian learning mechanisms synapses marine gastropod aplysia californicacitation needed experiments hebbian synapse modification mechanisms central nervous system synapses vertebrates much difficult control experiments relatively simple peripheral nervous system synapses studied marine invertebrates much work longlasting synaptic changes vertebrate neurons longterm potentiation involves use nonphysiological experimental stimulation brain cells however physiologically relevant synapse modification mechanisms studied vertebrate brains seem examples hebbian processes one reviews results experiments indicate longlasting changes synaptic strengths induced physiologically relevant synaptic activity working hebbian nonhebbian mechanisms point view artificial neurons artificial neural networks hebbs principle described method determining alter weights model neurons weight two neurons increases two neurons activate simultaneously reduces activate separately nodes tend either positive negative time strong positive weights tend opposite strong negative weights following formulaic description hebbian learning many descriptions possible w j displaystyle wij weight connection neuron j displaystyle j neuron displaystyle x displaystyle xi input neuron displaystyle note pattern learning weights updated every training example hopfield network connections w j displaystyle wij set zero j displaystyle ij reflexive connections allowed binary neurons activations either connections would set connected neurons activation pattern several training patterns used expression becomes average individual ones w j displaystyle wij weight connection neuron j displaystyle j neuron displaystyle p displaystyle p number training patterns x k displaystyle xik k displaystyle k th input neuron displaystyle average training patterns learning epoch weights updated training examples presented last term applicable discrete continuous training sets hopfield network connections w j displaystyle wij set zero j displaystyle ij reflexive connections variation hebbian learning takes account phenomena blocking many neural learning phenomena mathematical model harry klopfs model reproduces great many biological phenomena also simple implement simple nature hebbian learning based coincidence pre postsynaptic activity may intuitively clear form plasticity leads meaningful learning however shown hebbian plasticity pick statistical properties input way categorized unsupervised learning mathematically shown simplified example let us work simplifying assumption single ratebased neuron rate displaystyle yt whose inputs rates x x n displaystyle response neuron displaystyle yt usually described linear combination input w x displaystyle sum iwixi followed response function f displaystyle f defined previous sections hebbian plasticity describes evolution time synaptic weight w displaystyle w assuming simplicity identity response function f displaystyle faa write matrix form previous chapter training epoch done average displaystyle langle dots rangle discrete continuous time training set x displaystyle mathbf x done w η x x w η x x w η c w displaystyle frac dmathbf w dtlangle eta mathbf x mathbf x tmathbf w rangle eta langle mathbf x mathbf x trangle mathbf w eta cmathbf w c x x displaystyle clangle mathbf x mathbf x trangle correlation matrix input additional assumption x displaystyle langle mathbf x rangle ie average inputs zero system n displaystyle n coupled linear differential equations since c displaystyle c symmetric also diagonalizable solution found working eigenvectors basis form k displaystyle ki arbitrary constants c displaystyle mathbf c eigenvectors c displaystyle c α displaystyle alpha corresponding eigen values since correlation matrix always positivedefinite matrix eigenvalues positive one easily see solution always exponentially divergent time intrinsic problem due version hebbs rule unstable network dominant signal synaptic weights increase decrease exponentially intuitively whenever presynaptic neuron excites postsynaptic neuron weight reinforced causing even stronger excitation future forth selfreinforcing way one may think solution limit firing rate postsynaptic neuron adding nonlinear saturating response function f displaystyle f fact shown neuron model hebbs rule therefore network models neurons usually employ learning theories bcm theory ojas generalized hebbian algorithm regardless even unstable solution one see sufficient time passed one terms dominates others α displaystyle alpha largest eigenvalue c displaystyle c time postsynaptic neuron performs following operation c displaystyle mathbf c eigenvector corresponding largest eigenvalue correlation matrix x displaystyle xi corresponds exactly computing first principal component input mechanism extended performing full pca principal component analysis input adding postsynaptic neurons provided postsynaptic neurons prevented picking principal component example adding lateral inhibition postsynaptic layer thus connected hebbian learning pca elementary form unsupervised learning sense network pick useful statistical aspects input describe distilled way despite common use hebbian models longterm potentiation hebbs principle cover forms synaptic longterm plasticity hebb postulate rules inhibitory synapses make predictions anticausal spike sequences presynaptic neuron fires postsynaptic neuron synaptic modification may simply occur activated neurons b neighboring synapses forms hetero synaptic homeostatic plasticity therefore considered nonhebbian example retrograde signaling presynaptic compound commonly identified fulfilling retrograde transmitter role nitric oxide due high solubility diffusivity often exerts effects nearby type diffuse synaptic modification known volume learning included traditional hebbian hebbian learning spiketimingdependent plasticity used influential theory mirror neurons mirror neurons neurons fire individual performs action individual another perform similar action discovery neurons influential explaining individuals make sense actions others showing person perceives actions others person activates motor programs would use perform similar actions activation motor programs adds information perception helps predict person next based perceivers motor program challenge explain individuals come neurons respond performing action hearing seeing another perform similar actions christian keysers david perrett suggested individual performs particular action individual see hear feel performing action reafferent sensory signals trigger activity neurons responding sight sound feel action activity sensory neurons consistently overlap time motor neurons caused action hebbian learning predicts synapses connecting neurons responding sight sound feel action neurons triggering action potentiated true people look mirror hear babble imitated others repeated experience reafference synapses connecting sensory motor representations action strong motor neurons start firing sound vision action mirror neuron created evidence perspective comes many experiments show motor programs triggered novel auditory visual stimuli repeated pairing stimulus execution motor program review evidence see giudice et al instance people never played piano activate brain regions involved playing piano listening piano music five hours piano lessons participant exposed sound piano time press key proven sufficient trigger activity motor regions brain upon listening piano music heard later consistent fact spiketimingdependent plasticity occurs presynaptic neurons firing predicts postsynaptic neurons link sensory stimuli motor programs also seem potentiated stimulus contingent motor program httpsenwikipediaorgwikihebbiantheory