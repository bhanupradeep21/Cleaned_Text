spatial hearing loss refers form deafness inability use spatial cues sound originates space poor sound localization turn affects ability understand speech presence background people spatial hearing loss difficulty processing speech arrives one direction simultaneously filtering noise arriving directions research shown spatial hearing loss leading cause central auditory processing disorder capd children children spatial hearing loss commonly present difficulties understanding speech spatial hearing loss found people years age sometimes independent types age related hearing presbycusis spatial hearing loss varies age childhood adulthood viewed spatial hearing gain becoming easier hear speech noise middle age beyond spatial hearing loss begins becoming harder hear speech noise sound streams arriving left right horizontal plane localised primarily small time differences sound arriving two ears sound straight front head heard time ears sound side head heard approximately seconds later ear furthest away sound halfway one side heard approximately seconds later interaural time difference itd cue measured signal processing two central auditory pathways begin cochlea pass brainstem spatial hearing loss unable process itd low frequency cues sound streams arriving head head behind head vertical plane localised signal processing central auditory pathways cues time however notchespeaks added sound arriving ears complex shapes pinna different notchespeaks added sounds coming compared sounds coming compared sounds coming behind significant notches added sounds khz khz spatial hearing loss unable process pinna related high frequency cues time sound stream representations reach end auditory pathways brainstem inhibition processing ensures right pathway solely responsible left ear sounds left pathway solely responsible right ear responsibility auditory cortex ac right hemisphere map whole auditory scene information right auditory hemifield joins information left hemifield passed corpus callosum cc brain white matter connects homologous regions left right spatial hearing loss unable integrate auditory representations left right hemifields consequently unable maintain representation auditory space auditory space representation enables attention given conscious topdown driven single auditory stream gain mechanism employed involving enhancement speech stream suppression speech streams noise inhibition mechanism employed involving variable suppression outputs two spatial hearing loss unable suppress unwanted cochlea output individuals spatial hearing loss able accurately perceive directions different sound streams coming hearing longer sound streams rear may appear come front instead sound streams left right may appear come front gain mechanism used enhance speech stream interest sound streams spatial hearing loss need target speech raised typically db listening speech background noise compared spatial hearing spatial hearing ability normally begins develop early childhood continues develop early adulthood age years spatial hearing ability begins peripheral hearing central auditory pathway problems interfere early development individuals range different reasons maturation two ear spatial hearing ability may simply never happen example prolonged episodes ear infections glue ear likely significantly hinder many neuroscience studies facilitated development refinement speech processing model model shows cooperation two hemispheres brain asymmetric interhemispheric intrahemispheric connectivity consistent left hemisphere specialization phonological right hemisphere specialized sound auditory space representation brain requires integration information corpus callosum cc major route communication two hemispheres maturity large mass white matter consists bundles fibres linking white matter two cerebral hemispheres caudal splenium portions contain fibres originate primary second auditory cortices auditory responsive transcallosal interhemispheric transfer auditory information plays significant role spatial hearing functions depend binaural various studies shown despite normal audiograms children known auditory interhemispheric transfer deficits particular difficulty localizing sound understanding speech cc human brain relatively slow mature size continuing increase fourth decade life point slowly begins lisns srt scores show ability understand speech noisy environments develops age beginning adult like years starts decline years medial olivocochlear bundle moc part collection brainstem nuclei known superior olivary complex soc moc innervates outer hair cells cochlea activity able reduce basilarmembrane responses sound reducing gain cochlear quiet environment speech single talker listened moc efferent pathways essentially inactive case single speech stream enters ears representation ascends two auditory stream arrives right left auditory cortices eventual speech processing left hemisphere noisy environment moc efferent pathways required active two distinct ways first automatic response multiple sound streams arriving two ears second topdown corticofugal attention driven response purpose attempt enhance signal noise ratio speech stream listened sound automatic response involves moc efferents inhibiting output cochlear left ear output right ear therefore dominant right hemispace streams direct connection speech processing areas left hemisphere travel auditory children underdeveloped corpus callosum cc unable case transfer auditory streams arriving left ear right hemisphere left adults mature cc attention driven conscious decision attend one particular sound stream trigger moc spatial representation multiple streams noisy environment function right hemisphere enables choice ear attended consequence instruction may given moc efferents inhibit output right cochlear rather left speech stream attended left hemispace arrive right hemisphere access speech processing via cc spatial hearing loss diagnosed using listening spatialized noise sentences test designed assess ability children central auditory processing disorder capd understand speech background noise lisns allows audiologists measure well person uses spatial pitch information understand speech noise inability use spatial information found leading cause capd test participants repeat series target sentences presented simultaneously competing speech listeners speech reception threshold srt target sentences calculated using adaptive procedure targets perceived coming front listener whereas distracters vary according perceived spatially either directly front either side listener vocal identity distracters also varies either different speaker target performance lisns evaluated comparing listeners performances across four listening conditions generating two srt measures three advantage measures advantage measures represent benefit db gained either talker spatial talker spatial cues available listener use advantage measures minimizes influence higher order skills test serves control inevitable differences exist individuals functions language memory dichotic listening tests used measure efficacy attentional control cochlear inhibition interhemispheric transfer auditory information dichotic listening performance typically increases rightear advantage decreases development corpus callosum cc peaking fourth decade middle age older auditory system ages cc reduces size dichotic listening becomes worse primarily left dichotic listening tests typically involve two different auditory stimuli usually speech presented simultaneously one ear using set headphones participants asked attend one dividedattention test activity medial olivocochlear bundle moc inhibition cochlear gain measured using distortion product otoacoustic emission dpoe recording method involves contralateral presentation broadband noise measurement dpoae amplitudes latency onset dpoae suppression dpoae suppression significantly affected age becomes difficult detect approximately years research shown pc based spatial hearing training software help children identified failing develop spatial hearing skills perhaps frequent bouts otitis media research needed discover similar approach would help recover loss spatial hearing one study showed dichotic test scores left ear improved daily related research plasticity whitematter see lövdén et al suggests recovery may possible music training leads superior understanding speech noise across age groups musical experience protects agerelated degradation neural unlike speech fast temporal information music pitch information primarily processed areas brain right given seems likely right ear advantage rea speech present would follow left ear advantage music also present birth moc efferent inhibition right ear plays similar role creating advantage greater exposure music increase conscious control cochlear gain inhibition research needed explore apparent ability music promote enhanced capability speech noise recognition bilateral digital hearing aids preserve localization cues see example van den bogaert et al means audiologists fitting hearing aids patients mild moderate age related loss risk negatively impacting spatial hearing capability patients feel lack understanding speech background noise primary hearing difficulty hearing aids may simply make problem even worse spatial hearing gain reduced region db although research needed growing number studies shown openfit hearing aids better able preserve localisation cues see example alworth httpsenwikipediaorgwikispatialhearingloss