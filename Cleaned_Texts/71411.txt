dna sequencing theory broad body work attempts lay analytical foundations determining order specific nucleotides sequence dna otherwise known dna sequencing practical aspects revolve around designing optimizing sequencing projects known strategic genomics predicting project performance troubleshooting experimental results characterizing factors sequence bias effects software processing algorithms comparing various sequencing methods one another sense could considered branch systems engineering operations research permanent archive work primarily mathematical although numerical calculations often conducted particular problems dna sequencing theory addresses physical processes related sequencing dna confused theories analyzing resultant dna sequences eg sequence alignment sometimes make careful distinction latter primarily concerned algorithmic issues sequencing theory based elements mathematics biology systems engineering highly interdisciplinary subject may studied within context computational biology mainstream methods dna sequencing rely reading small fragments dna subsequently reconstructing data infer original dna target either via assembly alignment reference abstraction common methods mathematical covering example one imagine line segment representing target subsequent process smaller segments dropped onto random locations target target considered sequenced adequate coverage accumulates eg gaps remain abstract properties covering studied mathematicians however direct application results generally possible closedform mathematical solutions especially probability distributions often readily evaluated involve inordinately large amounts computer time parameters characteristic dna sequencing stevens configuration one results obtained perspective pure mathematics also account factors actually important sequencing instance detectable overlap sequencing fragments doublestranding edgeeffects target multiplicity consequently development sequencing theory proceeded according philosophy applied mathematics particular problemfocused makes expedient use approximations simulations etc earliest result may found directly elementary probability theory suppose model process taking l displaystyle l g displaystyle g fragment length target length respectively probability covering given location target one particular fragment l g displaystyle lg presumes l g displaystyle lll g valid often realworld cases probability single fragment covering given location target therefore l g displaystyle l g n displaystyle n displaystyle n fragments probability covering given location target least one fragment therefore equation first used characterize plasmid may appear modified form projects n displaystyle ngg good degree approximation r n l g displaystyle rnlg called redundancy note significance redundancy representing average number times position covered fragments note also considering covering process positions target probability identical expected value random variable c displaystyle c fraction target coverage final result remains widespread use back envelope estimator predicts coverage projects evolves along universal curve function redundancy eric lander michael waterman published important examining covering problem standpoint gaps although focused socalled mapping problem abstraction sequencing much furnished number useful results adopted standard theory earliest days largescale genome model also used designing human genome project continues play important role dna sequencing ultimately main goal sequencing project close gaps gap perspective logical basis developing sequencing model one frequently used results model expected number contigs given number fragments sequenced one neglects amount sequence essentially wasted detect overlaps theory yields published improvements theory enabling applied sequencing projects goal completely sequence target genome michael wendl bob confirmed based stevens models produced similar results number contigs substantial low coverage mapping sequencing projects sequencing projects ramped projects approached completion low coverage approximations became inadequate exact model roach necessary however cost sequencing dropped parameters sequencing projects became easier directly test empirically interest funding strategic genomics diminished basic ideas theory led number additional results particular variations mapping however technological advancements rendered mapping theories largely obsolete except organisms highly studied model organisms eg yeast flies mice humans parking strategy sequencing resembles process parking cars along curb car sequenced clone curb genomic clone sequenced screened ensure subsequently sequenced clones overlap previously sequenced clone sequencing effort redundant strategy however much like gaps parked cars unsequenced gaps less length clone accumulate sequenced clones considerable cost close gaps roach et proposed demonstrated simulations generalization set strategies explored earlier edwards wholegenome sequencing method became immensely popular championed celera used sequence several model organisms celera applied human genome today sequencing projects employ strategy often called paired end sequencing physical processes protocols dna sequencing continued evolve largely driven advancements biochemical methods instrumentation automation techniques wide range problems dna sequencing made inroads including metagenomics medical cancer sequencing important factors scenarios classical theory account recent work begun focus resolving effects issues level mathematics becomes commensurately sophisticated biologists developed methods filter highlyrepetitive essentially unsequenceable regions genomes procedures important organisms whose genomes consist mostly dna example corn yield multitudes small islands sequenceable dna products wendl proposed extension theory account gaps target due filtering socalled edgeeffect latter positionspecific sampling bias example terminal base position g displaystyle chance covered opposed l g displaystyle lg interior positions r displaystyle classical theory still gives good predictions dynamics change higher redundancies modern sequencing methods usually sequence ends larger fragment provides linking information de novo assembly improved probabilities alignment reference sequence researchers generally believe longer lengths data read lengths enhance performance large dna targets idea consistent predictions distribution however showed smaller fragments provide better coverage small linear targets reduce edge effect linear molecules findings implications sequencing products dna filtering procedures readpairing fragment size evidently negligible influence large wholegenome class targets sequencing emerging important tool medicine example cancer research ability detect heterozygous mutations important done sequence diploid genome obtained pioneering efforts sequence individuals levy et wheeler et sequenced craig venter jim watson respectively outlined models covering alleles genome wendl followed general theory allowed arbitrary number coverings allele arbitrary ploidy results point general conclusion amount data needed projects significantly higher traditional haploid projects generally least redundancy ie nucleotide spanned average sequence reads however requirements even greater depending upon kinds genomic events found example socalled discordant read pairs method dna insertions inferred distance read pairs larger expected calculations show around redundancy needed avoid falsepositive errors advent nextgeneration sequencing also made largescale population sequencing feasible example genomes project characterize variation human population groups common variation easily captured rare variation poses design challenge samples significant sequence redundancy risks variant sample group large samples light redundancy risk capturing variant read set actually sample group wendl report simple set optimization rules maximize probability discovery given set parameters example observing rare allele least twice eliminate possibility unique individual little less redundancy used regardless sample size nextgeneration instruments also enabling sequencing whole uncultured metagenomic communities sequencing scenario complicated various ways framing design theories given project example developed probabilistic model amount sequence needed obtain least one contig given size novel organism community wendl et al reported analysis average contig size probability completely recovering novel organism given rareness within conversely hooper et al propose semiempirical model based gamma dna sequencing theories often invoke assumption certain random variables model independent identically distributed example theory sequenced fragment presumed probability covering region genome fragments assumed independent one another actuality sequencing projects subject various types bias including differences well regions cloned sequencing anomalies biases target sequence random softwaredependent errors biases general theory agree well observation point enough data generated expose latent kinds biases related underlying target sequence particularly difficult model since sequence may known priori presents type logic problem httpsenwikipediaorgwikidnasequencingtheory