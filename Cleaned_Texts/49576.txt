visual servoing also known visionbased robot control abbreviated vs technique uses feedback information extracted vision sensor visual control motion robot one earliest papers talks visual servoing sri international labs two fundamental configurations robot endeffector hand visual servoing control techniques broadly classified following ibvs proposed weiss control law based error current desired features image plane involve estimate pose target features may coordinates visual features lines moments regions ibvs motions large rotations come called camera pbvs modelbased technique single camera pose object interest estimated respect camera command issued robot controller turn controls robot case image features extracted well additionally used estimate information pose object cartesian space hence servoing hybrid approaches use combination servoing different approaches hybrid servoing following description prior work divided parts visual servo systems also called servoing around since early although term visual servo coined visual servoing essence method robot control sensor used camera visual sensor servoing consists primarily two one involves using information image directly control degrees freedom dof robot thus referred image based visual servoing ibvs involves geometric interpretation information extracted camera estimating pose target parameters camera assuming basic model target known servoing classifications exist based variations component servoing system eg location camera two kinds eyeinhand configurations based control loop two kinds endpointopenloop endpointclosedloop based whether control applied joints dof directly position command robot controller two types direct servoing dynamic lookandmove one earliest works authors proposed hierarchical visual servo scheme applied imagebased servoing technique relies assumption good set features extracted object interest eg edges corners centroids used partial model along global models scene robot control strategy applied simulation two three dof robot arm feddema et introduced idea generating task trajectory respect feature velocity ensure sensors rendered ineffective stopping feedback robot motions authors assume objects known priori eg cad model features extracted object work espiau et discusses basic questions visual servoing discussions concentrate modeling interaction matrix camera visual features points lines etc adaptive servoing system proposed lookandmove servoing architecture method used optical flow along ssd provide confidence metric stochastic controller kalman filtering control scheme system assumes examples plane camera plane features discusses approach velocity control using jacobian relationship addition author uses kalman filtering assuming extracted position target inherent errors sensor errors model target velocity developed used feedforward input control loop also mentions importance looking kinematic discrepancy dynamic effects repeatability settling time oscillations lag response corke poses set critical questions visual servoing tries elaborate implications paper primarily focuses dynamics visual servoing author tries address problems like lag stability also talking feedforward paths control loop paper also tries seek justification trajectory generation methodology axis control development performance metrics chaumette provides good insight two major problems ibvs one servoing local minima second reaching jacobian singularity author show image points alone make good features due occurrence singularities paper continues discussing possible additional checks prevent singularities namely condition numbers js jˆs check null space ˆ js jts one main point author highlights relation local minima unrealizable image feature motions years many hybrid techniques involve computing partialcomplete pose epipolar geometry using multiple views multiple cameras values obtained direct estimation learning statistical scheme others used switching approach changes imagebased positionbased based lyapnov early hybrid techniques used combination imagebased posebased information approaches servoing required either full partial model object order extract pose information used variety techniques extract motion information used affine motion model image motion addition rough polyhedral cad model extract object pose respect camera able servo onto object lines pbvs visual servoing developed malis et well known technique breaks information required servoing organized fashion decouples rotations translations papers assume desired pose known priori rotational information obtained partial pose estimation homography essentially information giving axis rotation angle computing eigenvalues eigenvectors homography translational information obtained image directly tracking set feature points conditions feature points tracked never leave field view depth estimate predetermined offline technique servoing shown stable techniques preceded another interesting observation formulation authors claim visual jacobian singularities motions hybrid technique developed corke popularly called portioned approach partitions visual image jacobian motions rotations translations relating x axes motions related z outlines technique break columns visual jacobian correspond z axis translation rotation namely third sixth columns partitioned approach shown handle chaumette conundrum discussed technique requires good depth estimate order function properly outlines hybrid approach servoing task split two namely main secondary main task keep features interest within field view secondary task mark fixation point use reference bring camera desired pose technique need depth estimate offline procedure paper discusses two examples depth estimates obtained robot odometry assuming features plane secondary task achieved using notion parallax features tracked chosen initialization performed first frame typically points carries discussion two aspects visual servoing feature modeling modelbased tracking primary assumption made model object available authors highlights notion ideal features chosen dof motion decoupled linear relation authors also introduce estimate target velocity interaction matrix improve tracking performance results compared well known servoing techniques even occlusions occur section discusses work done field visual servoing try track various techniques use features work used image points visual features formulation interaction matrix assumes points image used represent target body work deviates use points use feature regions lines image moments moment authors discuss affine based tracking image features image features chosen based discrepancy measure based deformation features undergo features used texture patches one key points paper highlighted need look features improving visual servoing authors look choice image features question also discussed context tracking effect choice image features control law discussed respect depth axis authors consider distance feature points area object features features used control law slightly different forms highlight effects performance noted better performance achieved servo error proportional change depth axis provides one early discussions use moments authors provide new formulation interaction matrix using velocity moments image albeit complicated even though moments used moments small change location contour points use green theorem paper also tries determine set features plane dof robot discusses use image moments formulate visual jacobian formulation allows decoupling dof based type moments chosen simple case formulation notionally similar time variation moments determined using motion two images greens theorem relation velocity screw v given lmij v technique avoids camera calibration assuming objects planar using depth estimate technique works well planar case tends complicated general case basic idea based work moment invariants used key idea find feature vector decouples dof motion observations made centralized moments invariant translations complicated polynomial form developed rotations technique follows teachingbyshowing hence requiring values desired depth area object assuming plane camera object parallel object planar parts feature vector invariants authors claim occlusions handled build work described major differ ence authors use technique similar task broken two case features parallel cam era plane virtual rotation performed bring featured parallel camera consolidates work done authors image moments espiau showed purely experimental work image based visual servoing ibvs robust calibration errors author used camera explicit calibration along point matching without pose estimation paper looks effect errors uncertainty terms interaction matrix experimental approach targets used points assumed planar similar study done authors carry experimental evaluation uncalibrated visual servo systems popular major outcome experimental evidence effectiveness visual servo control conventional control methods kyrki et analyze servoing errors position based visual servoing technique involves determining error extracting image position propagating pose estimation servoing control points image mapped points world priori obtain mapping basically homography although explicitly stated paper mapping broken pure rotations translations pose estimation performed using standard technique computer vision pixel errors transformed pose propagating controller observation analysis shows errors image plane proportional depth error depthaxis proportional square depth measurement errors visual servoing looked extensively error functions relate two aspects visual servoing one steady state error servoed two stability control loop servoing errors interest arise pose estimation camera calibration authors extend work done considering global stability presence intrinsic extrinsic calibration provides approach bound task function tracking error authors use teachingbyshowing visual servoing technique desired pose known priori robot moved given pose main aim paper determine upper bound positioning error due image noise using convex optimization technique provides discussion stability analysis respect uncertainty depth estimates authors conclude paper observation unknown target geometry accurate depth estimate required order limit error many visual servoing techniques implicitly assume one object present image relevant feature tracking along area object available techniques require either partial pose estimate precise depth estimate current desired pose httpsenwikipediaorgwikivisualservoing