audio deepfake also known voice cloning type artificial intelligence used create convincing speech sentences sound like specific people saying things technology initially developed various applications improve human life example used produce also help people lost voices due throat disease medical problems get commercially opened door several opportunities technology also create personalized digital assistants naturalsounding texttospeech well speech translation services audio deepfakes recently called audio manipulations becoming widely accessible using simple mobile devices personal tools also used spread misinformation using led cybersecurity concerns among global public side effects using audio deepfakes including possible role disseminating misinformation disinformation audiobased social media people use logical access voice spoofing used manipulate public opinion propaganda defamation terrorism vast amounts voice recordings daily transmitted internet spoofing detection audio deepfake attackers targeted individuals organizations including politicians early scammers used artificial intelligencebased software impersonate voice ceo authorize money transfer million phone according global mcafee survey one person ten reported targeted ai voice cloning scam targets reported losing money audio deepfakes could also pose danger voice id systems currently deployed financial audio deepfakes divided three different categories replaybased deepfakes malicious works aim reproduce recording interlocutors two types farfield detection cutandpaste detection farfield detection microphone recording victim played test segment handsfree hand cutandpaste involves faking requested sentence textdependent textdependent speaker verification used defend replaybased current technique detects endtoend replay attacks use deep convolutional neural category based speech synthesis refers artificial production human speech using software hardware system programs speech synthesis includes texttospeech aims transform text acceptable natural speech making speech sound line text input using rules linguistic description text classical system type consists three modules text analysis model acoustic model vocoder generation usually follow two essential steps necessary collect clean wellstructured raw audio transcripted text original speech audio sentence second texttospeech model must trained using data build synthetic audio generation model specifically transcribed text target speakers voice input generation model text analysis module processes input text converts linguistic features acoustic module extracts parameters target speaker audio data based linguistic features generated text analysis finally vocoder learns create vocal waveforms based parameters acoustic features final audio file generated including synthetic simulation audio waveform format creating speech audio voice many speakers even training first breakthrough regard introduced neural network generating raw audio waveforms capable emulating characteristics many different speakers network overtaken years synthesize highly realistic artificial voices within everyone texttospeech highly dependent quality voice corpus used realize system creating entire voice corpus expensivecitation needed another disadvantage speech synthesis systems recognize periods special characters also ambiguity problems persistent two words written way different meaningscitation needed audio deepfake based imitation way transforming original speech one speaker original sounds spoken like another speaker target imitationbased algorithm takes spoken signal input alters changing style intonation prosody trying mimic target voice without changing linguistic technique also known voice conversion method often confused previous syntheticbased method clear separation two approaches regarding generation process indeed methods modify acousticspectral style characteristics speech audio signal imitationbased usually keeps input output text unaltered obtained changing sentence spoken match target speakers voices imitated several ways using humans similar voices mimic original speaker recent years popular approach involves use particular neural networks called generative adversarial networks gan due flexibility well highquality original audio signal transformed say speech target audio using imitation generation method generates new speech shown fake one audio deepfake detection task determines whether given speech audio real fake recently become hot topic forensic research community trying keep rapid evolution counterfeiting techniques general deepfake detection methods divided two categories based aspect leverage perform detection task first focuses lowlevel aspects looking artifacts introduced generators sample level second instead focus higherlevel features representing complex aspects semantic content speech audio recording many machine learning deep learning models developed using different strategies detect fake audio time algorithms follow threesteps procedure years many researchers shown machine learning approaches accurate deep learning methods regardless features however scalability machine learning methods confirmed due excessive training manual feature extraction especially many audio files instead deep learning algorithms used specific transformations required audio files ensure algorithms handle several opensource implementations different detection usually many research groups release public hosting service like github audio deepfake recent field research reason many possibilities development improvement well possible threats adopting technology bring daily lives important ones listed regarding generation significant aspect credibility victim ie perceptual quality audio deepfake several metrics determine level accuracy audio deepfake generation widely used mos mean opinion score arithmetic average user ratings usually test rated involves perceptual evaluation sentences made different speech generation algorithms index showed audio generated algorithms trained single speaker higher sampling rate also plays essential role detecting generating audio deepfakes currently available datasets sampling rate around khz significantly reducing speech quality increase sampling rate could lead higher quality focusing detection part one principal weakness affecting recent models adopted language studies focus detecting audio deepfake english language paying much attention spoken languages like chinese well hindi arabic also essential consider factors related different accents represent way pronunciation strictly associated particular individual location nation fields audio speaker recognition accent found influence performance expected feature could affect models performance even detection task addition excessive preprocessing audio data led high often unsustainable computational cost reason many researchers suggested following selfsupervised learning dealing unlabeled data work effectively detection tasks improving models scalability time decreasing computational cost training testing models real audio data still underdeveloped area indeed using audio realworld background noises increase robustness fake audio detection models addition effort focused detecting syntheticbased audio deepfakes studies analyzing imitationbased due intrinsic difficulty generation years increase techniques aimed defending malicious actions audio deepfake could bring identity theft manipulation speeches nations governors prevent deepfakes suggest using blockchain distributed ledger technologies dlt identify provenance data track extracting comparing affective cues corresponding perceived emotions digital content also proposed combat another critical aspect concerns mitigation problem suggested would better keep proprietary detection tools need factcheckers way create generation models perhaps nefarious purposes would know precisely features facilitate detection discouraging possible attackers improve detection instead researchers trying generalize looking preprocessing techniques improve performance testing different loss functions used numerous research groups worldwide working recognize media manipulations ie audio deepfakes also image video deepfake projects usually supported public private funding close contact universities research institutions purpose defense advanced research projects agency darpa runs semantic forensics leveraging research media forensics program also darpa semantic detection algorithms determine whether media object generated manipulated automate analysis media provenance uncover intent behind falsification various another research program preserving media trustworthiness artificial intelligence era program funded italian ministry education university research miur run five italian universities premier pursue novel hybrid approaches obtain forensic detectors interpretable publicly available dataset intended research purposes develop systems detect speech generated neural networks process called retrievalbased voice conversion rvc preliminary research showed numerous statisticallysignificant differences features found human speech generated artificial intelligence algorithms last years numerous challenges organized push field audio deepfake research even famous world challenge automatic speaker verification spoofing countermeasures challenge challenge biannual communityled initiative aims promote consideration spoofing development another recent challenge deepfake considers fake situations reallife also voice conversion biannual challenge created need compare different voice conversion systems approaches using voice data httpsenwikipediaorgwikiaudiodeepfake