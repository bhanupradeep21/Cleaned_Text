bcm theory bcm synaptic modification bcm rule named elie bienenstock leon cooper paul munro physical theory learning visual cortex developed bcm model proposes sliding threshold longterm potentiation ltp longterm depression ltd induction states synaptic plasticity stabilized dynamic adaptation timeaveraged postsynaptic activity according bcm model presynaptic neuron fires postsynaptic neurons tend undergo ltp highactivity state eg firing high frequency andor high internal calcium concentrations ltd loweractivity state eg firing low frequency low internal calcium theory often used explain cortical neurons undergo ltp ltd depending different conditioning stimulus protocols applied presynaptic neurons usually highfrequency stimulation hfs ltp lowfrequency stimulation lfs donald hebb proposed working mechanism memory computational adaption brain called hebbian learning maxim cells fire together wire notion foundational modern understanding brain neural network though universally true remains good first approximation supported decades however hebbs rule problems namely mechanism connections get weaker upper bound strong get words model unstable theoretically computationally later modifications gradually improved hebbs rule normalizing allowing decay synapses activity unsynchronized activity neurons results loss connection strength new biological evidence brought activity peak theorists formalized various approximations theory use firing frequency instead potential determining neuron excitation assumption ideal importantly linear synaptic integration signals unexpected behavior adding input currents determine whether cell fire approximations resulted basic form bcm final step came form mathematical analysis prove stability computational analysis prove applicability culminating bienenstock cooper munros paper since experiments shown evidence bcm behavior visual cortex hippocampus latter plays important role formation storage memories areas wellstudied experimentally theory experiment yet establish conclusive synaptic behavior areas brain proposed cerebellum parallelfiber purkinje cell synapse follows inverse bcm rule meaning time parallel fiber activation high calcium concentration purkinje cell results ltd lower concentration results furthermore biological implementation synaptic plasticity bcm yet basic bcm rule takes form model modified form hebbian learning rule j c j displaystyle dot mjcdj requires suitable choice function ϕ displaystyle phi avoid hebbian problems instability bienenstock al rewrite ϕ c displaystyle phi c function ϕ c c displaystyle phi cbar c c displaystyle bar c time average c displaystyle c modification discarding uniform decay rule takes vectorial form conditions stable learning derived rigorously bcm noting c displaystyle cttextbf mtcdot textbf dt approximation average output c displaystyle bar ctapprox textbf mtbar mathbf sufficient equivalently threshold θ c c c p c displaystyle theta mbar cbar c p displaystyle p c displaystyle fixed positive implemented theory often taken τ displaystyle tau time constant selectivity model drawbacks requires longterm potentiation longterm depression increases decreases synaptic strength something observed cortical systems requires variable activation threshold depends strongly stability selected fixed points c displaystyle p displaystyle p however models strength incorporates requirements independently derived rules stability normalizability decay function time proportional square example particular case one chapter mathematical results bienenstock al work assuming p displaystyle c displaystyle values θ c c p c c displaystyle theta mbar cbar decide ϕ c c c c θ displaystyle phi cbar ccctheta fulfills stability conditions said previous chapter assume two presynaptic neurons provides inputs displaystyle displaystyle activity repetitive cycle half time displaystyle mathbf remainder time displaystyle mathbf c displaystyle bar c time average average c displaystyle c value first second half cycle let initial value weights displaystyle mathbf first half time displaystyle mathbf displaystyle mathbf weighted sum c displaystyle c equal use value initial average c displaystyle bar c means θ displaystyle theta ϕ displaystyle phi displaystyle dot adding derivative weights obtain new ones displaystyle mathbf next half time inputs displaystyle mathbf weights displaystyle mathbf means c displaystyle c displaystyle bar c full cycle θ displaystyle theta ϕ displaystyle phi displaystyle dot adding derivative weights obtain new ones displaystyle mathbf repeating previous cycle obtain several hundred iterations stability reached displaystyle mathbf c displaystyle csqrt first half c displaystyle remainder time c displaystyle bar csqrt θ displaystyle theta msqrt ϕ displaystyle phi displaystyle dot note predicted final weight vector displaystyle become orthogonal one input patterns final values c displaystyle c intervals zeros function ϕ displaystyle phi first major experimental confirmation bcm came investigating ltp ltd hippocampus serena dudeks experimental work showed qualitative agreement final form bcm activation experiment later replicated visual cortex bcm originally designed work provided evidence necessity variable threshold function stability hebbiantype learning bcm others experimental evidence nonspecific bcm rittenhouse et al confirmed bcms prediction synapse modification visual cortex one eye selectively closed specifically n displaystyle overline describes variance spontaneous activity noise closed eye displaystyle time since closure experiment agreed general shape prediction provided explanation dynamics monocular eye closure monocular deprivation versus binocular eye experimental results far conclusive far favored bcm competing theories plasticity algorithm bcm complicated largescale parallel distributed processing put use lateral networks furthermore existing computational network learning algorithms made correspond bcm httpsenwikipediaorgwikibcmtheory